# hippo-coder 成员
唐子博 , 张开源 , 金睿智 , 杨森
# 数据获取
## 调研数据集

## 爬取-数据处理
1. 通过脚本爬取文件列表,主要包括repo_id和下载地址
2. 读取文件列表,下载文件
3. 通过脚本,对下载得到的文件进行解压
4. 对解压后的数据进行提取 , 提取代码文件 , 该文件属于大文件 , 可能涉及分布式数据处理操作

# 数据切分
0. 数据预处理,去除头部的声明相关的注释,或则相关的版权注释
1. 对每个文件进行打分,打分根据文件分数倒叙
   a. 分数很低我们不要(分数数据数据分布来看什么是高什么是低)
2. 根据文件长度,确定数据分布情况(这个分布的情况其实就是用户习惯),就可以得到两个阈值,太小的丢掉(或则根据关系进行拼接[考虑未来优化]),太大的要裁剪(逻辑不能断[边界判断])
3. 进行文件切块,切块都得trunk size 的分布,应该也基本符合第二点的分布情况

# 根据数据块,获取sft数据

